
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">Introduction<a class="anchor-link" href="#Introduction">&#182;</a></h2><p><strong>Sentiment analysis</strong> is an important application of natural language processing, as it makes it possible to predict what a person thinks given the text she has written.</p>
<p>For example, let's say you own a company and you would like to monitor the opinion of your customers on twitter. It's fairly easy to detect the tweets in which your company or products is mentioned, and to find out how many times these tweets are liked or retweeted.</p>
<p>But tweets and likes do not mean that people like what you're doing! Maybe they're just destroying the reputation of your company online, or they like a funny tweet in which somebody says your products are really bad.</p>
<p>That's where sentiment analysis is needed: it will tell you whether the tweet is positive or negative for your company, and how you should interpret all these likes and retweets.</p>
<p>This post is the third part of my tutorial series about natural language processing with the <a href="https://www.yelp.com/dataset">yelp dataset</a>. You will learn how to classify the reviews of the yelp dataset as positive or negative with two different deep neural networks.</p>
<p>First, we will try a simple network consisting of an <strong>embedding layer</strong>, a <strong>dense layer</strong>, and a final <strong>sigmoid neuron</strong>.</p>
<p>Then, we will see how <strong>convolutional layers</strong> can help us improve performance.</p>
<p>If you don't know the terms used above, you can refer to these tutorials:</p>
<ul>
<li><strong>embedding</strong> is explained in <a href="https://thedatafrog.com/word-embedding-sentiment-analysis/">word embedding and simple sentiment analysis</a>;</li>
<li><strong>dense layers</strong> are introduced in <a href="https://thedatafrog.com/handwritten-digit-recognition-scikit-learn/">handwritten digit recognition with scikit-learn</a>;</li>
<li><strong>the sigmoid neuron</strong> is described in details in <a href="https://thedatafrog.com/logistic-regression/">the 1-neuron network: logistic regression</a>;</li>
<li><strong>convolutional layers</strong> are described at length in <a href="https://thedatafrog.com/deep-learning-keras/">tuning a deep convolutional network for image recognition, with keras and tensorflow</a></li>
</ul>
<h2 id="How-to-run-this-tutorial">How to run this tutorial<a class="anchor-link" href="#How-to-run-this-tutorial">&#182;</a></h2><p>A GPU will save you a lot of time, as we want to train fairly complex networks on a large number of events here.</p>
<p>To get access to a GPU for your training, you can simply run this tutorial on the Google Colaboratory platform by clicking <a href="https://colab.research.google.com/github/cbernet/maldives/blob/master/yelp/yelp_simplenet.ipynb">this link</a>. Make sure to change the runtime to run on a GPU.</p>
<p>The other possibility is to use your own machine. Install Anaconda for python 3.X, TensorFlow, and keras on <a href="https://thedatafrog.com/install-tensorflow-windows/">Windows</a> or <a href="https://thedatafrog.com/install-tensorflow-ubuntu/">Linux</a>. Then:</p>
<ul>
<li>get <a href="https://github.com/cbernet/maldives/archive/master.zip">the repository containing this notebook</a>, and unpack the archive</li>
<li>start the jupyter notebook</li>
<li>navigate to the <code>yelp</code> directory, and open <code>yelp_simplenet.ipynb</code> </li>
</ul>
<p>Now let's initialize our tools:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># the usual stuff: </span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">keras</span>

<span class="c1"># get reproducible results</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="k">import</span> <span class="n">seed</span>
<span class="n">seed</span><span class="p">(</span><span class="mh">0xdeadbeef</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="k">import</span> <span class="n">set_random_seed</span>
<span class="n">set_random_seed</span><span class="p">(</span><span class="mh">0xdeadbeef</span><span class="p">)</span>

<span class="c1"># needed to run on a mac: </span>
<span class="kn">import</span> <span class="nn">os</span> 
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;KMP_DUPLICATE_LIB_OK&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;True&#39;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-dataset">The dataset<a class="anchor-link" href="#The-dataset">&#182;</a></h2><p>The reviews of the <a href="https://www.yelp.com/dataset">yelp dataset</a> come as a very large JSON lines file containing the reviews in plain text, together with the corresponding rating and some more information. The reviews look like this:</p>

<pre><code>{"review_id":"Q1sbwvVQXV2734tPgoKj4Q","user_id":"hG7b0MtEbXx5QzbzE6C_VA",
"business_id":"ujmEBvifdJM6h6RLv4wQIg",
"stars":1.0,"useful":6,"funny":1,"cool":0,
"text":"Total bill for this horrible service? Over $8Gs. These crooks actually had the nerve to charge us $69 for 3 pills. I checked online the pills can be had for 19 cents EACH! Avoid Hospital ERs at all costs.","date":"2013-05-07 04:34:36"}</code></pre>
<p>This file needs to be preprocessed for machine learning. Indeed, to feed the review text to a neural network, we need to convert it to an array of numbers in some way, a task called encoding.</p>
<p>You can follow <a href="https://thedatafrog.com/text-preprocessing-machine-learning-yelp/">this tutorial</a> to see how to download the dataset and to do the preprocessing yourself.</p>
<p>Alternatively, you can obtain the necessary files <a href="https://drive.google.com/open?id=1mIcl7ubm60LfbhV59btIlsAn7DuV2-PB">here</a>:</p>
<ul>
<li><code>data.h5</code> contains the dataset. It's basically a large numpy array</li>
<li><code>index.pck</code> contains the vocabulary, which will be used to convert the numbers representing the words back into text in case we want to investigate our data. </li>
</ul>
<p>I'm sorry, but at the moment, I do not know how to access these files directly from Google Colab. So if you want to run there, you will need to first download the files locally, and then to <a href="https://colab.research.google.com/notebooks/io.ipynb">upload them to Google Colab</a> (just add a cell to this notebook to do that). This means the files will be transferred twice.</p>
<p>If you run on your own machine, you should put these files in the same directory as the <code>yelp_simplenet.ipynb</code> notebook.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now let's open our dataset file. This is an hdf5 file, so we use the h5py package to open it.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">h5py</span>
<span class="c1"># datadir = &#39;/data2/cbernet/maldives/yelp_dataset/&#39;</span>
<span class="n">datadir</span> <span class="o">=</span> <span class="s1">&#39;./&#39;</span>
<span class="n">datafile</span> <span class="o">=</span> <span class="n">datadir</span><span class="o">+</span><span class="s1">&#39;data.h5&#39;</span>
<span class="n">h5</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">datafile</span><span class="p">)</span>
<span class="n">h5</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[6]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;KeysViewHDF5 [&#39;reviews&#39;]&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can use the dataset already as a numpy array. h5py will load in memory only the the data you need to complete a given operation. For example, here is the shape of the array:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">h5</span><span class="p">[</span><span class="s1">&#39;reviews&#39;</span><span class="p">]</span>
<span class="n">data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[7]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(6685900, 254)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>and let's check the first line:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[8]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([    5,     1,     0,     0,   696,    26,    39,  3348,    26,
        1523,    44,   336,    64,    14,   153,  5179,  2731,    24,
          72,   172,  4377,   125,   257,  3044,  6568, 10127,  8410,
           3,    33,   277,   219,   501,  8900,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0], dtype=int16)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>At preprocessing stage, when I created this array, I decided to reserve the first four slots on each line for:</p>
<ul>
<li>the number of stars; </li>
<li>the number of "useful" votes;</li>
<li>the number of "funny" votes;</li>
<li>the number of "cool" votes.</li>
</ul>
<p>The reviewer gave 5 stars (the maximum rating) to this company, and somebody considered his review helpful.</p>
<p>After the first four slots come the codes for the review text. I allocated 250 slots for the reviews. If the review contains more than 250 words, it's truncated. If it contains less that 250 words, as is the case here, the unused slots are filled with zeros.</p>
<p>We can decode this review with the vocabulary:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># load the vocabulary object from index.pck</span>
<span class="kn">import</span> <span class="nn">pickle</span> 
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">datadir</span><span class="o">+</span><span class="s1">&#39;index.pck&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">pckf</span><span class="p">:</span> 
    <span class="n">vocab</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">pckf</span><span class="p">)</span>
<span class="c1"># selecting the text of the first review,</span>
<span class="c1"># excluding the first 4 slots</span>
<span class="n">first_review</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">:]</span>
<span class="c1"># the decoding returns a list of words, </span>
<span class="c1"># and we join the words with spaces</span>
<span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span> <span class="n">vocab</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">first_review</span><span class="p">)</span> <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[9]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;helped out when locked out apartment he quick got at price lowest comparison all other area definately recommend top master situations requiring locksmith they get job done quickly effectively &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt;&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's extract the information needed to train our neural networks.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># the reviews</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">4</span><span class="p">:]</span>
<span class="c1"># the stars, from which we will</span>
<span class="c1"># obtain the labels (see below)</span>
<span class="n">stars</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># additional features we might consider:</span>
<span class="n">useful</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">cool</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span>
<span class="n">funny</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span><span class="mi">3</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our goal is to predict whether the review text is positive or negative. Therefore, we need to label our examples in two categories: 0 (negative) and 1 (positive). We can use the number of stars to define these categories. For example, we could say that a review with 3 stars or more is positive.</p>
<p>First, let's check the distribution of stars:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">stars</span><span class="p">[:</span><span class="mi">1000</span><span class="p">],</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">5.5</span><span class="p">),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[11]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(array([  0., 137.,  81., 108., 238., 436.]),
 array([-0.5,  0.5,  1.5,  2.5,  3.5,  4.5,  5.5]),
 &lt;a list of 6 Patch objects&gt;)</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADLFJREFUeJzt3W2IpfV5x/Hvrz4kwbSx0YnI7tIRspRIoBoWEYRSNC0+EX0Ri9ImNizsGwsGC+mmb0qgL/RNtIUSkChd2xCVmKKotBUfCELUzPqUmm3qVrZxUbIbfEgkpMXk6ov5L53ujjtnZs54dq5+PzDMff/PvWeuG/G7N/ecczZVhSSpr1+b9QCSpI1l6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNXfyrAcAOPPMM2t+fn7WY0jSprJ3796fVNXcSsedEKGfn59nYWFh1mNI0qaS5D8nOc5bN5LUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktTcCfHOWElajfndD816hKk5cPMVG/4zvKKXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc1NHPokJyV5LsmDY/+cJE8neTnJPUlOHesfGPv7x+PzGzO6JGkSq7mivxHYt2T/FuDWqtoOvAnsHOs7gTer6uPAreM4SdKMTBT6JFuBK4Cvj/0AFwPfGofsAa4e21eNfcbjl4zjJUkzMOkV/W3Al4Bfjf0zgLeq6t2xfxDYMra3AK8CjMffHsdLkmZgxdAnuRI4VFV7ly4vc2hN8NjS592VZCHJwuHDhycaVpK0epNc0V8EfCbJAeBuFm/Z3AacnuTIv1C1FXhtbB8EtgGMxz8CvHH0k1bV7VW1o6p2zM3NreskJEnvbcXQV9WXq2prVc0D1wKPVdUfAY8Dnx2HXQ/cP7YfGPuMxx+rqmOu6CVJ74/1vI7+z4Gbkuxn8R78HWP9DuCMsX4TsHt9I0qS1mNV/zh4VT0BPDG2XwEuWOaYXwDXTGE2SdIU+M5YSWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpuRVDn+SDSZ5J8kKSl5J8Zayfk+TpJC8nuSfJqWP9A2N//3h8fmNPQZJ0PJNc0f8XcHFV/Q5wHnBpkguBW4Bbq2o78Cawcxy/E3izqj4O3DqOkyTNyIqhr0XvjN1TxlcBFwPfGut7gKvH9lVjn/H4JUkytYklSasy0T36JCcleR44BDwC/AfwVlW9Ow45CGwZ21uAVwHG428DZyzznLuSLCRZOHz48PrOQpL0niYKfVX9sqrOA7YCFwCfWO6w8X25q/c6ZqHq9qraUVU75ubmJp1XkrRKq3rVTVW9BTwBXAicnuTk8dBW4LWxfRDYBjAe/wjwxjSGlSSt3iSvuplLcvrY/hDwaWAf8Djw2XHY9cD9Y/uBsc94/LGqOuaKXpL0/jh55UM4G9iT5CQW/2K4t6oeTPID4O4kfwU8B9wxjr8D+Psk+1m8kr92A+aWJE1oxdBX1YvA+cusv8Li/fqj138BXDOV6SRJ6+Y7YyWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDV38qwHkPT+mN/90KxH0Ix4RS9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktTciqFPsi3J40n2JXkpyY1j/aNJHkny8vj+m2M9Sf4myf4kLyb51EafhCTpvU1yRf8u8GdV9QngQuCGJOcCu4FHq2o78OjYB7gM2D6+dgFfm/rUkqSJrRj6qnq9qp4d2z8D9gFbgKuAPeOwPcDVY/sq4K5a9BRwepKzpz65JGkiq7pHn2QeOB94Gjirql6Hxb8MgI+Nw7YAry75YwfHmiRpBiYOfZIPA/cBX6yqnx7v0GXWapnn25VkIcnC4cOHJx1DkrRKE4U+ySksRv4bVfXtsfzjI7dkxvdDY/0gsG3JH98KvHb0c1bV7VW1o6p2zM3NrXV+SdIKJnnVTYA7gH1V9dUlDz0AXD+2rwfuX7L++fHqmwuBt4/c4pEkvf8m+cfBLwI+B3w/yfNj7S+Am4F7k+wEfgRcMx57GLgc2A/8HPjCVCeWJK3KiqGvqidZ/r47wCXLHF/ADeucS5I0Jb4zVpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaO3nWA+h/ze9+aNYjTM2Bm6+Y9QiSBq/oJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6Smlvx0yuT3AlcCRyqqk+OtY8C9wDzwAHgD6vqzSQB/hq4HPg58CdV9ezGjC5tvE6fKKr/vya5ov874NKj1nYDj1bVduDRsQ9wGbB9fO0CvjadMSVJa7Vi6KvqO8AbRy1fBewZ23uAq5es31WLngJOT3L2tIaVJK3eWu/Rn1VVrwOM7x8b61uAV5ccd3CsHSPJriQLSRYOHz68xjEkSSuZ9i9js8xaLXdgVd1eVTuqasfc3NyUx5AkHbHW0P/4yC2Z8f3QWD8IbFty3FbgtbWPJ0lar7WG/gHg+rF9PXD/kvXPZ9GFwNtHbvFIkmZjkpdXfhP4PeDMJAeBvwRuBu5NshP4EXDNOPxhFl9auZ/Fl1d+YQNmliStwoqhr6rr3uOhS5Y5toAb1juUJGl6fGesJDVn6CWpOUMvSc2teI9eWgs/I0Y6cXhFL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqbkNCn+TSJD9Msj/J7o34GZKkyUw99ElOAv4WuAw4F7guybnT/jmSpMlsxBX9BcD+qnqlqv4buBu4agN+jiRpAhsR+i3Aq0v2D441SdIMnLwBz5ll1uqYg5JdwK6x+06SH27ALNN0JvCTWQ8xBV3OAzyXE1WXc3lfziO3rOuP/9YkB21E6A8C25bsbwVeO/qgqroduH0Dfv6GSLJQVTtmPcd6dTkP8FxOVF3Opct5wMbcuvkesD3JOUlOBa4FHtiAnyNJmsDUr+ir6t0kfwr8M3AScGdVvTTtnyNJmsxG3Lqhqh4GHt6I556hTXObaQVdzgM8lxNVl3Ppch6k6pjfk0qSGvEjECSpOUO/gi4f55DkziSHkvzrrGdZryTbkjyeZF+Sl5LcOOuZ1iLJB5M8k+SFcR5fmfVM65XkpCTPJXlw1rOsR5IDSb6f5PkkC7OeZ728dXMc4+Mc/h34fRZfNvo94Lqq+sFMB1uDJL8LvAPcVVWfnPU865HkbODsqno2ya8De4GrN9t/lyQBTquqd5KcAjwJ3FhVT814tDVLchOwA/iNqrpy1vOsVZIDwI6q6vB+AK/oV9Dm4xyq6jvAG7OeYxqq6vWqenZs/wzYxyZ893UtemfsnjK+Nu2VV5KtwBXA12c9i/4vQ398fpzDCS7JPHA+8PRsJ1mbcavjeeAQ8EhVbcrzGG4DvgT8ataDTEEB/5Jk73gX/6Zm6I9voo9z0Gwk+TBwH/DFqvrprOdZi6r6ZVWdx+I7yC9IsilvqyW5EjhUVXtnPcuUXFRVn2LxU3hvGLc+Ny1Df3wTfZyD3n/jnvZ9wDeq6tuznme9quot4Ang0hmPslYXAZ8Z97bvBi5O8g+zHWntquq18f0Q8I8s3sbdtAz98flxDieg8UvMO4B9VfXVWc+zVknmkpw+tj8EfBr4t9lOtTZV9eWq2lpV8yz+f/JYVf3xjMdakySnjV/yk+Q04A+ATf1qNUN/HFX1LnDk4xz2Afdu1o9zSPJN4LvAbyc5mGTnrGdah4uAz7F41fj8+Lp81kOtwdnA40leZPGi4pGq2tQvS2ziLODJJC8AzwAPVdU/zXimdfHllZLUnFf0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKa+x/3rfIGYPRMGgAAAABJRU5ErkJggg==
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Please note that the number of stars ranges from 1 to 5, so it's not possible for a reviewer to give no star.</p>
<p>Then, we want to split the dataset in two categories that have roughly the same number of examples.</p>
<p>If we were to define as positive the examples with 3 stars or more, the positive category would be much larger than the negative one.</p>
<p>I prefer to define as positive all reviews with 4 stars or more. Technically, here is how to define the targets:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># first fill an array with zeros, </span>
<span class="c1"># with the same shape as stars</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">stars</span><span class="p">)</span>
<span class="c1"># then write 1 if the number of stars is 4 or 5</span>
<span class="n">y</span><span class="p">[</span><span class="n">stars</span><span class="o">&gt;</span><span class="mf">3.5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stars</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">stars</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[1 0 1 ... 0 0 0] 6685900
[5 3 5 ... 1 1 3] 6685900
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As usual, we split the dataset into a training and a test sample. At first, we will use 20000 examples for the test sample, and "only" 100,000 examples for the training sample:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_test</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="n">n_test</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_test</span><span class="p">]</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">n_test</span><span class="p">:</span><span class="n">n_train</span><span class="o">+</span><span class="n">n_test</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">n_test</span><span class="p">:</span><span class="n">n_train</span><span class="o">+</span><span class="n">n_test</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sentiment-analysis-with-a-simple-dense-network">Sentiment analysis with a simple dense network<a class="anchor-link" href="#Sentiment-analysis-with-a-simple-dense-network">&#182;</a></h2><p>Our first deep neural network will contain:</p>
<ul>
<li>an embedding layer <ul>
<li>cf. <a href="https://thedatafrog.com/word-embedding-sentiment-analysis">word embedding and simple sentiment analysis</a> for more information about embedding</li>
</ul>
</li>
<li>a dense layer, responsible for interpreting the results of the embedding<ul>
<li>cf. <a href="https://thedatafrog.com/handwritten-digit-recognition-scikit-learn/">handwritten digit recognition with scikit-learn</a> for a beginner introduction to dense neural networks</li>
</ul>
</li>
<li>a final sigmoid neuron that will output the probability for the review to be positive <ul>
<li>cf. <a href="https://thedatafrog.com/logistic-regression/">the 1-neuron network: logistic regression</a> for a detailed discussion of the final sigmoid neuron.</li>
</ul>
</li>
</ul>
<p>We start by creating an empty model:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The first layer will be the embedding layer. Its role is to convert each integer representing a word into a vector in N-dimensional space. In this space, words with similar meaning will be grouped together.</p>
<p>Following the <a href="https://keras.io/layers/embeddings/">keras documentation</a>, we indicate the number of possible words, the dimension of the embedding space, and the maximum size of the text.</p>
<p>We start with a 2-dimensional embedding space, as we had done in <a href="https://thedatafrog.com/word-embedding-sentiment-analysis">word embedding and simple sentiment analysis</a>. That's a very low number of dimensions. In fact, typically, embedding is done in 10-100 dimensions.</p>
<p>But as usual, it's good to start small. We will try and increase the number of dimensions of the embedding space later to see if it improves performance.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">review_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">words</span><span class="p">),</span> <span class="mi">2</span><span class="p">,</span> 
                                 <span class="n">input_length</span><span class="o">=</span><span class="n">review_length</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The output of the embedding is multidimensional. Indeed, we start with a 1D array with 250 words. Since embedding gives us a two-dimensional vector for each word, the embedding layer spits out an array of shape (250, 2). This 2D array cannot be used directly as input to a dense layer, so we need to flatten it into a 1D array with 500 slots. This is done by the Flatten layer:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then, we add dropout regularization. In a nutshell, the dropout regularization layer drops, on a random basis, a fraction of its input values. This forces the network to learn different paths to solve the problem, and helps reduce <a href="https://thedatafrog.com/overfitting-illustrated/">overfitting</a>. If you want to know a bit more about dropout regularization, <a href="https://thedatafrog.com/deep-learning-keras/#Dropout-layers">check this out</a>.</p>
<p>Here we decide to drop 40% of the values from the Flatten layer:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.4</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After that, we can add a dense layer, which will analyze the results of the embedding. Again, we start small, with only 5 neurons. We will see later if performance can be improved by increasing the number of neurons.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And finally, we end with a dense layer consisting of a single neuron with a <a href="https://thedatafrog.com/logistic-regression/">sigmoid activation function</a>. Therefore, this neuron will produce a value between 0 and 1, which is the estimated probability for the example review to be positive.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can now compile and print the full model:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 250, 2)            40004     
_________________________________________________________________
flatten_1 (Flatten)          (None, 500)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 500)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 5)                 2505      
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 6         
=================================================================
Total params: 42,515
Trainable params: 42,515
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We fit the model on the training dataset:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">,</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 100000 samples, validate on 20000 samples
Epoch 1/10
100000/100000 [==============================] - 8s 79us/step - loss: 0.6192 - acc: 0.6719 - val_loss: 0.5592 - val_acc: 0.7271
Epoch 2/10
100000/100000 [==============================] - 7s 67us/step - loss: 0.4592 - acc: 0.7890 - val_loss: 0.3570 - val_acc: 0.8552
Epoch 3/10
100000/100000 [==============================] - 7s 67us/step - loss: 0.3297 - acc: 0.8627 - val_loss: 0.2888 - val_acc: 0.8851
Epoch 4/10
100000/100000 [==============================] - 7s 67us/step - loss: 0.2865 - acc: 0.8851 - val_loss: 0.2647 - val_acc: 0.9003
Epoch 5/10
100000/100000 [==============================] - 7s 67us/step - loss: 0.2662 - acc: 0.8928 - val_loss: 0.2549 - val_acc: 0.9004
Epoch 6/10
100000/100000 [==============================] - 7s 73us/step - loss: 0.2557 - acc: 0.8976 - val_loss: 0.2500 - val_acc: 0.9020
Epoch 7/10
100000/100000 [==============================] - 8s 80us/step - loss: 0.2464 - acc: 0.9026 - val_loss: 0.2510 - val_acc: 0.9054
Epoch 8/10
100000/100000 [==============================] - 7s 69us/step - loss: 0.2402 - acc: 0.9049 - val_loss: 0.2463 - val_acc: 0.9073
Epoch 9/10
100000/100000 [==============================] - 7s 69us/step - loss: 0.2347 - acc: 0.9069 - val_loss: 0.2470 - val_acc: 0.9067
Epoch 10/10
100000/100000 [==============================] - 7s 70us/step - loss: 0.2302 - acc: 0.9084 - val_loss: 0.2477 - val_acc: 0.9044
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We see that we end up with a validation accuracy of about 90%. To have a look at the performance in more details, we will use the following function:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="k">def</span> <span class="nf">plot_accuracy</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">miny</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Plot the training and validation accuracy&#39;&#39;&#39;</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">]</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_acc&#39;</span><span class="p">]</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">miny</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">miny</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    
<span class="n">plot_accuracy</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">miny</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>&lt;Figure size 432x288 with 0 Axes&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The training accuracy plateaus at 90%, so training further will not help much.</p>
<p>What we see here is that this network underfits the data, meaning that architecture is not complex enough to fit the data. By making it more complex, the training and testing accuracies can certainly be improved. A visual illustration of underfitting is shown <a href="https://thedatafrog.com/overfitting-illustrated/#So-why-do-we-need-complex-networks-then?">here</a>.</p>
<h2 id="Dense-network:-increasing-complexity">Dense network: increasing complexity<a class="anchor-link" href="#Dense-network:-increasing-complexity">&#182;</a></h2><p>After some tuning, I converged to the following architecture. The structure of the network is complex, so I use the full dataset to avoid overfitting.</p>
<p>You can now execute the cell below and go grab a coffee.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_test</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="n">n_test</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_test</span><span class="p">]</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">n_test</span><span class="p">:]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">n_test</span><span class="p">:]</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">words</span><span class="p">),</span> <span class="mi">128</span><span class="p">,</span> 
                                 <span class="n">input_length</span><span class="o">=</span><span class="n">review_length</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.4</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">,</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_3 (Embedding)      (None, 250, 128)          2560256   
_________________________________________________________________
flatten_3 (Flatten)          (None, 32000)             0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 32000)             0         
_________________________________________________________________
dense_7 (Dense)              (None, 100)               3200100   
_________________________________________________________________
dense_8 (Dense)              (None, 100)               10100     
_________________________________________________________________
dense_9 (Dense)              (None, 100)               10100     
_________________________________________________________________
dense_10 (Dense)             (None, 1)                 101       
=================================================================
Total params: 5,780,657
Trainable params: 5,780,657
Non-trainable params: 0
_________________________________________________________________
Train on 6665900 samples, validate on 20000 samples
Epoch 1/3
6665900/6665900 [==============================] - 160s 24us/step - loss: 0.2113 - acc: 0.9129 - val_loss: 0.1897 - val_acc: 0.9235
Epoch 2/3
6665900/6665900 [==============================] - 160s 24us/step - loss: 0.1880 - acc: 0.9233 - val_loss: 0.1834 - val_acc: 0.9260
Epoch 3/3
6665900/6665900 [==============================] - 160s 24us/step - loss: 0.1743 - acc: 0.9294 - val_loss: 0.1811 - val_acc: 0.9252
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_accuracy</span><span class="p">(</span><span class="n">history</span><span class="p">,</span><span class="n">miny</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>&lt;Figure size 432x288 with 0 Axes&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That's an improvement over the previous attempt, but the training is quite long, and it seems we will not be able to reach 93% classification accuracy on the test sample with this technique. In the next section we try a different strategy.</p>
<h2 id="Sentiment-analysis-with-a-convolutional-network">Sentiment analysis with a convolutional network<a class="anchor-link" href="#Sentiment-analysis-with-a-convolutional-network">&#182;</a></h2><p>We introduced convolutional layers when we tuned a <a href="https://thedatafrog.com/deep-learning-keras/">deep convolutional network for image recognition</a>.</p>
<p>In this tutorial, the convolutional layer consists of a small window called the kernel which scans the image and extracts features at each position. The great advantage of convolutional layers for image recognition is that they can recognize parts of an image wherever these parts are in the image. Also, convolutional layers consider the pixels of the kernel together, which allows them to find local relationships between these pixels.</p>
<p>In natural language processing, we deal with a sentence, not an image, but we can make the following analogies:</p>
<ul>
<li>image: sentence</li>
<li>pixel: word</li>
<li>2D convolution: 1D convolution</li>
</ul>
<p>In this section, we will introduce a 1D convolutional layer in our network, with a kernel size of 3. The following sentences illustrate how the convolutional layer will deal with a given review. At each step, the kernel moves by one word, and the words currently scanned by the kernel are indicated in boldface:</p>
<ul>
<li><strong>this movie is</strong> really not good</li>
<li>this <strong>movie is really</strong> not good</li>
<li>this movie <strong>is really not</strong> good</li>
<li>this movie is <strong>really not good</strong> </li>
</ul>
<p><strong>really not good</strong> carries a lot of information for our sentiment analysis. The convolutional layer will find it whatever its position in the sentence. Also, it will be easy for the network to understand the meaning of <strong>not good</strong>. On the contrary, in our previous attempt, <strong>not</strong> and <strong>good</strong> are not directly considered together.</p>
<p>Let's try. In the example below, the convolutional layer is set up with:</p>
<ul>
<li>a kernel size of 3,</li>
<li>64 filters. This means that 64 features (values) will be extracted from each position of the kernel,</li>
<li>a ReLU activation, as usual. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_test</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="mi">1000000</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="n">n_test</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_test</span><span class="p">]</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">n_test</span><span class="p">:</span><span class="n">n_test</span><span class="o">+</span><span class="n">n_train</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">n_test</span><span class="p">:</span><span class="n">n_test</span><span class="o">+</span><span class="n">n_train</span><span class="p">]</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">words</span><span class="p">),</span> <span class="mi">64</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="mi">250</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.4</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">,</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_4 (Embedding)      (None, 250, 64)           1280128   
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 248, 64)           12352     
_________________________________________________________________
flatten_4 (Flatten)          (None, 15872)             0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 15872)             0         
_________________________________________________________________
dense_11 (Dense)             (None, 50)                793650    
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 51        
=================================================================
Total params: 2,086,181
Trainable params: 2,086,181
Non-trainable params: 0
_________________________________________________________________
Train on 1000000 samples, validate on 20000 samples
Epoch 1/3
1000000/1000000 [==============================] - 24s 24us/step - loss: 0.2351 - acc: 0.9030 - val_loss: 0.1978 - val_acc: 0.9219
Epoch 2/3
1000000/1000000 [==============================] - 23s 23us/step - loss: 0.1876 - acc: 0.9264 - val_loss: 0.1927 - val_acc: 0.9251
Epoch 3/3
1000000/1000000 [==============================] - 23s 23us/step - loss: 0.1703 - acc: 0.9340 - val_loss: 0.1859 - val_acc: 0.9286
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_accuracy</span><span class="p">(</span><span class="n">history</span><span class="p">,</span><span class="n">miny</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>&lt;Figure size 432x288 with 0 Axes&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With the convolutional layer, we get the same performance as with our best try with a simple dense network. However, please note that:</p>
<ul>
<li>there are only 2 million parameters in the network, instead of 10 million</li>
<li>the convolutional network is less subject to overfitting, and we could restrict the number of training examples to 1 million instead of 6.7 millions, and the training was much faster</li>
<li>there is room for optimization </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Stacked-convolutional-layers">Stacked convolutional layers<a class="anchor-link" href="#Stacked-convolutional-layers">&#182;</a></h2><p>In this section, we will optimize our convolutional network further by stacking convolutional layers.</p>
<p>As we have done in <a href="https://thedatafrog.com/deep-learning-keras/">Tuning a deep convolutional network for image recognition</a>, we perform <strong>max pooling</strong> between each convolutional layer, and the layers extract more and more features as we progress in the network.</p>
<p>To avoid overfitting, we use the whole dataset for training except for 20000 events that are kept for testing.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_test</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="n">n_test</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_test</span><span class="p">]</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">n_test</span><span class="p">:]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">n_test</span><span class="p">:]</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">words</span><span class="p">),</span> <span class="mi">64</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="mi">250</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling1D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling1D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span>
                    <span class="n">y_train</span><span class="p">,</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_5 (Embedding)      (None, 250, 64)           1280128   
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 250, 16)           3088      
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 125, 16)           0         
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 125, 32)           1568      
_________________________________________________________________
max_pooling1d_2 (MaxPooling1 (None, 62, 32)            0         
_________________________________________________________________
conv1d_4 (Conv1D)            (None, 62, 64)            6208      
_________________________________________________________________
flatten_5 (Flatten)          (None, 3968)              0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 3968)              0         
_________________________________________________________________
dense_13 (Dense)             (None, 100)               396900    
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 101       
=================================================================
Total params: 1,687,993
Trainable params: 1,687,993
Non-trainable params: 0
_________________________________________________________________
Train on 6665900 samples, validate on 20000 samples
Epoch 1/4
6665900/6665900 [==============================] - 135s 20us/step - loss: 0.1826 - acc: 0.9268 - val_loss: 0.1642 - val_acc: 0.9343
Epoch 2/4
6665900/6665900 [==============================] - 135s 20us/step - loss: 0.1598 - acc: 0.9366 - val_loss: 0.1604 - val_acc: 0.9373
Epoch 3/4
6665900/6665900 [==============================] - 135s 20us/step - loss: 0.1511 - acc: 0.9404 - val_loss: 0.1587 - val_acc: 0.9368
Epoch 4/4
6665900/6665900 [==============================] - 135s 20us/step - loss: 0.1446 - acc: 0.9431 - val_loss: 0.1592 - val_acc: 0.9368
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_accuracy</span><span class="p">(</span><span class="n">history</span><span class="p">,</span><span class="n">miny</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>&lt;Figure size 432x288 with 0 Axes&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Nice! 93.7% accuracy, and only a tiny bit of overfitting. There is probably some room for optimization, so please let us know in the comments if you manage to do better with convolutional layers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Investigating-the-misclassified-reviews">Investigating the misclassified reviews<a class="anchor-link" href="#Investigating-the-misclassified-reviews">&#182;</a></h2><p>It's always interesting to look at misclassified examples to get a hint of what's going on and maybe get ideas for further improvements. That's what we're going to do now, with the first 100 examples.</p>
<p>Here are the predictions and the true labels for these samples:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[32]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_sample</span> <span class="o">=</span> <span class="n">x_test</span>
<span class="n">y_sample</span> <span class="o">=</span> <span class="n">y_test</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">x_sample</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;true:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_sample</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predictions:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>true:
[1 0 1 ... 0 1 1]
predictions:
[1 1 1 ... 0 1 1]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, we select the misclassified examples, together with the true label and the prediction for these examples:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[33]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">idx</span> <span class="o">=</span> <span class="n">preds</span><span class="o">!=</span><span class="n">y_sample</span>
<span class="n">miscl</span> <span class="o">=</span> <span class="n">x_sample</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span class="n">miscl_pred</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span class="n">miscl_true</span> <span class="o">=</span> <span class="n">y_sample</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we print the first five:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[34]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">pred</span><span class="p">,</span> <span class="n">true</span><span class="p">,</span> <span class="n">rev</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">miscl_pred</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span> <span class="n">miscl_true</span><span class="p">,</span> <span class="n">miscl</span><span class="p">[:</span><span class="mi">5</span><span class="p">]):</span>
    <span class="n">rev</span> <span class="o">=</span> <span class="n">rev</span><span class="p">[</span><span class="n">rev</span><span class="o">!=</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># remove padding</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">true</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">rev</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>1 0
on wet snowy sunday afternoon made trek out famous fairmount bagels since st. close decided pick up some from there as well compare each other as well as bagels all name research people ! fairmount vs. st. bagels from both locations were fresh from oven still warm when they were handed us ca n&#39;t say preferred one over other eventually bagels from both locations were mixed up could n&#39;t pick out which ones came from where they were also both great with cream cheese &amp; smoked salmon montreal vs. ny : both respectable their own way ny counterparts &amp; thicker can taken more seriously as meal montreal bagels thinner with more crust crumb ratio best eaten as snack love snacks overall enjoy all bagels refuse play this silly game favorites


1 0
went this little cozy restaurant with wife quiet intimate romantic resto with attentive owner unpretentious capable staff had crab croquettes caesar salad had salmon ( delicious ! crispy on outside perfectly flaky on inside ) desserts : tiramisu wife had chocolate brownie with ice cream very fine tasty meal


1 0
happy when found out they have fish company at downtown food not as fresh as one stripe like one stripe better even they have same menu


0 1
this review parent or someone will visit with child without child would completely different review as most would find space not relaxing where take your child indoor ? other than y or play there very few options this place completely kid friendly play area fenced off from eating area set up kids from infant 4 or 5 there two washrooms change table unsupervised but parent can sit cafe observe or go play area they have cups drinks play area cafe has great food drinks local and/or organic chose pricey review as an adult sandwich $ 10 kid sandwich $ 5.75 plus $ 5 play time first kid room strollers hang coats staff super nice helpful


0 1
this not review as such hope try this place on next visit vegas but question opening hours on yelp listed as 11:00 - however people have left reviews stating they have visited after midnight which when will probably visiting does anyone know actual opening hours ? thanks


</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It's not too easy to understand the reviews with all the missing words, especially the stop words like "the", "I", "a", etc. Still, let's try.</p>
<ul>
<li>1st review: it seems that this person is comparing two bagel shops. She seems to like both and to refuse to compare them. Still, his rating is negative... </li>
<li>2nd review: the text is clearly super positive but the rating is negative... </li>
<li>3rd review: this person clearly states that this is not a review, and that she wants to ask a question about opening hours...</li>
<li>4th review: this is a mixed review. I understand that the food is very good but that the restaurant is too expensive and that there were a few issues. The person still recommends to try it once. </li>
<li>5th review: again a mixed review. </li>
</ul>
<p>So it appears we're not doing so bad: among the 5 misclassified reviews, three are weird. The last two ones correspond to borderline cases.</p>
<p>We can build a pandas dataframe to look at the first 5 misclassified reviews. I know that these misclassified reviews are among the first 100 examples, so I will restrict the dataframe to this range:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[35]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="c1"># take the first 4 columns of the first 100 examples. </span>
<span class="c1"># give meaningful names to these columns</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">[:</span><span class="mi">100</span><span class="p">,:</span><span class="mi">4</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;stars&#39;</span><span class="p">,</span><span class="s1">&#39;useful&#39;</span><span class="p">,</span><span class="s1">&#39;funny&#39;</span><span class="p">,</span><span class="s1">&#39;cool&#39;</span><span class="p">])</span>
<span class="c1"># add a column to mark misclassified reviews: </span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;misc&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span>
<span class="c1"># print the misclassified lines: </span>
<span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;misc&#39;</span><span class="p">]</span><span class="o">==</span><span class="kc">True</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[35]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stars</th>
      <th>useful</th>
      <th>funny</th>
      <th>cool</th>
      <th>misc</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>5</td>
      <td>2</td>
      <td>3</td>
      <td>True</td>
    </tr>
    <tr>
      <th>7</th>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>33</th>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>35</th>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>True</td>
    </tr>
    <tr>
      <th>36</th>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>43</th>
      <td>4</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We don't learn much, only that these reviews are indeed borderline: they have 3 or 4 stars, and we set the boundary between our negative and positive categories between 3 and 4 stars.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We're done. Now let's <a href="https://thedatafrog.com/sentiment-analysis-convolutional-network#wrapup">go back and wrap up!</a></p>

</div>
</div>
</div>
 

