{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this tutorial \n",
    "\n",
    "To do deep learning in practice, you need a Graphics Processing Unit (GPU). Or the time needed to train your deep neural nets on the CPU of your machine will be prohibitive.\n",
    "\n",
    "We have seen how to [install TensorFlow on Windows](https://thedatafrog.com/install-tensorflow-windows/) and [on Linux](https://thedatafrog.com/install-tensorflow-ubuntu/), which is useful if you have an nvidia graphics card in your PC. \n",
    "\n",
    "But what if you don't? \n",
    "\n",
    "If you just want to learn deep learning, there is a very easy solution that requires **no specific hardware or software**, the Colaboratory platform from Google.\n",
    "\n",
    "Let's try and use it for the first time. \n",
    "\n",
    "In this tutorial, you will learn: \n",
    "\n",
    "* What is the google colaboratory platform and how to use it. \n",
    "* How to set up a first convolutional neural network to recognize handwritten digits with very high accuracy \n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "* Please have a look at [my first tutorial on handwritten digits](https://thedatafrog.com/handwritten-digit-recognition-scikit-learn/). This will show you which kind of performance we can get without deep learning, and will teach you the basics of numpy, matplotlib, and neural networks. \n",
    "* You should know a bit of [Keras](https://thedatafrog.com/first-neural-network-keras/)\n",
    "\n",
    "\n",
    "## Google Colaboratory Platorm\n",
    "\n",
    "Google set up the [Colaboratory Platform](https://colab.research.google.com/notebooks/welcome.ipynb) to promote the use of TensorFlow for deep learning, and it's awesome! \n",
    "\n",
    "It provides: \n",
    "\n",
    "* python environments with all the necessary software, and you can install more if needed\n",
    "* access to GPUs\n",
    "* excellent tutorials\n",
    "* the possibility to run your own code (and my stuff!)\n",
    "\n",
    "In particular, the author of Keras and google engineer FranÃ§ois Chollet set up extremely useful tutorials in which Keras is used as an interface to TensorFlow, such as [this one](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/fashion_mnist.ipynb) where we learn how to classify clothing items (trousers, shoes, and whatnot). \n",
    "\n",
    "I do encourage you to dig into the google colab tutorials on your own! I would only advise you to stick to the keras-based tutorials which are much easier. \n",
    "\n",
    "On my side, I intend to use this tool to provide you with original content, and more details about the subjects already covered by google. \n",
    "\n",
    "ðŸ’¡ **To run your jupyter notebook on google colab, you just need to commit it to github, and to provide a specific url to direct google colab to the notebook.**\n",
    "\n",
    "The url of this tutorial on github is https://github.com/cbernet/maldives/blob/master/hwd_deeplearning_google/hwd_dl_google.ipynb\n",
    "\n",
    "The url to run it on google colab is https://colab.research.google.com/github/cbernet/maldives/blob/master/hwd_deeplearning_google/hwd_dl_google.ipynb\n",
    "\n",
    "Just follow this link now, and click on CONNECT on the top right side. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "In [my first tutorial on handwritten digits](https://thedatafrog.com/handwritten-digit-recognition-scikit-learn/), we have used the simplify digits dataset provided with scikit-learn for simplicity, and because we didn't have the resources to process the [real MNIST handrwitten digits dataset](http://yann.lecun.com/exdb/mnist/) at that time. \n",
    "\n",
    "Here, we have access to TensorFlow, which provides an easy access to this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so: \n",
    "\n",
    "* 60,000 training samples and 10,000 test samples\n",
    "* images are 28x28 = 784 pixels, while they are 8x8=64 pixels in the digits dataset of sckikit-learn. We have images with much better resolution, but need networks with many more neurons to process them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot some of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_img(i):\n",
    "    # plot the image and the target for sample i\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.title(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_img(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please have a look at other images by repeating the plot above for different samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should check the actual data for a given image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the values in the image array are between 0 and 255 (the value seems to be coded on 8 bits). \n",
    "\n",
    "This is not adequate. Indeed, for a neural network to work well, it must deal with input values close to unity, and the weights in the network should be kept small. So we're going to normalize all images to values between 0. and 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_train = np.divide(x_train, 255.)\n",
    "print np.amax(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.divide(x_test, 255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also check our targets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the reasons explained in [our first keras tutorial](https://thedatafrog.com/first-neural-network-keras/), we're going to perform one-hot encoding on the targets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "print y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
