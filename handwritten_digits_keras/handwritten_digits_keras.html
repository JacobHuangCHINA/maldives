<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="About-this-tutorial">About this tutorial<a class="anchor-link" href="#About-this-tutorial">&#182;</a></h2><p>In my post about <a href="https://thedatafrog.com/handwritten-digit-recognition-scikit-learn/">handwritten digit recognition with scikit-learn</a>, we have seen that a simple neural network can easily be trained with <a href="https://scikit-learn.org">scikit-learn</a>. And we managed to classify images of digits with an accuracy larger than 90%.</p>
<p>But scikit-learn is generally not adapted to neural networks.</p>
<p>Its goal is in fact to provide a unified interface for training and testing different machine learning algorithms: neural networks, and also support-vector machines, naive Bayes, nearest neighbours, decision trees, etc.</p>
<p>Indeed, in machine learning projects, you'll spend a large fraction of your time choosing the best algorithm and tuning it for best performance. Scikit-learn was designed to make these tasks as easy as possible.</p>
<p>However, when it comes to neural networks specifically, scikit-learn has two major drawbacks:</p>
<ul>
<li>the interface does not provide enough control to build complex neural networks, nor to control their behaviour in details.</li>
<li>it's not adapted to <a href="https://thedatafrog.com/install-tensorflow-windows/">deep learning</a></li>
</ul>
<p>In this post, we will repeat our exercise about handwritten digit recognition with <a href="https://keras.io/">Keras</a>, a high-level neural networks API. You will learn:</p>
<ul>
<li>How to install Keras </li>
<li>How to create a simple dense neural network with this tool </li>
<li>How to estimate its performance </li>
</ul>
<p>Later on, we will use Keras as an interface to TensorFlow to do deep learning.</p>
<p><strong>Prerequisites:</strong> You should have some knowledge of:</p>
<ul>
<li>numpy, </li>
<li>matplotlib, </li>
<li>jupyter notebooks,</li>
<li>basic neural networks. </li>
</ul>
<p>If that's not the case, <a href="https://thedatafrog.com/handwritten-digit-recognition-scikit-learn/">handwritten digit recognition with scikit-learn</a> is just for you!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Installation">Installation<a class="anchor-link" href="#Installation">&#182;</a></h2><p>First, install <a href="https://www.anaconda.com/download/">Anaconda</a> if not already done.</p>
<p>Launch the Anaconda Navigator application.</p>
<p>Enter the Environments tab, and install the keras package in your base (root) environment.</p>
<p>Solving the package specifications for keras may take a few minutes but you'll eventually get there.</p>
<p>Then, head to the Home tab, and launch the jupyter notebook.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, get this notebook and open it in the jupyter notebook:</p>
<ul>
<li><a href="https://github.com/cbernet/maldives/archive/master.zip">download the repository containing this notebook</a></li>
<li>unzip it, say to <code>Downloads/maldives-master</code></li>
<li>in the jupyter notebook, navigate to <code>Downloads/maldives-master/handwritten_digits_keras</code></li>
<li>open <code>handwritten_digits_keras.ipynb</code></li>
</ul>
<p>This page should appear in the notebook. From now on, follow the tutorial in the notebook.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preparing-the-dataset">Preparing the dataset<a class="anchor-link" href="#Preparing-the-dataset">&#182;</a></h2><p>As in <a href="https://thedatafrog.com/handwritten-digit-recognition-scikit-learn/">handwritten digit recognition with scikit-learn</a>, we are going to use the digits dataset provided by scikit-learn. The digits are 8x8 images and we will feed them to a neural network with:</p>
<ul>
<li>an input layer with 8x8 = 64 neurons</li>
<li>a hidden layer with 15 neurons</li>
<li>an output layer with 10 neurons corresponding to the 10 digit categories. </li>
</ul>
<p>First, let's initialize our tools and load the digits dataset:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">os</span> 
<span class="c1"># for some reason, the following is needed to run on mac os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;KMP_DUPLICATE_LIB_OK&#39;</span><span class="p">]</span><span class="o">=</span><span class="s1">&#39;True&#39;</span>  

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">datasets</span>
<span class="n">digits</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_digits</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The input layer requires a 1-dimensional array in input, but our images are 2D. So we need to flatten all images:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">x</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[2]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(1797, 64)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The labels require a bit of attention. At the moment, <code>digits.target</code> contains the digit corresponding to each image in the dataset:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">digits</span><span class="o">.</span><span class="n">target</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[3]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([0, 1, 2, ..., 8, 9, 8])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>But in Keras, we have to build our neural network with 10 output neurons (this actually happens under the hood in scikit-learn). During the training, Keras will have to compare the 10 output values of these neurons to the target value. But how can we compare a vector of 10 values with a single target value?</p>
<p>The solution is to translate each target value into a vector of length 10 with a technique called <em>one-hot encoding</em>:</p>
<ul>
<li>target <code>0</code> is translated to <code>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</code></li>
<li>target <code>1</code> is translated to <code>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</code></li>
<li>...</li>
<li>target <code>9</code> is translated to <code>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</code></li>
</ul>
<p>After doing that, the values from the output neurons, which are probabilities ranging from 0 to 1, can be compared directly to the values in the target vector. In this way, for a given number, say 0, the neural network will be trained to output a high probability from the first output neuron, and a low probability from the following neurons.</p>
<p>One-hot encoding can be performed easily with the utilities provided by Keras:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.utils</span> <span class="k">import</span> <span class="n">np_utils</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np_utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[0 1 2 ... 8 9 8]
[[1. 0. 0. ... 0. 0. 0.]
 [0. 1. 0. ... 0. 0. 0.]
 [0. 0. 1. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 1. 0.]
 [0. 0. 0. ... 0. 0. 1.]
 [0. 0. 0. ... 0. 1. 0.]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>let's now split our data into a training sample and a testing sample:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">split_limit</span><span class="o">=</span><span class="mi">1000</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="n">split_limit</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">split_limit</span><span class="p">]</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">split_limit</span><span class="p">:]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">split_limit</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The first 1000 images and labels are going to be used for training. The rest of the dataset will be used later to test the performance of our network.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Creation-of-the-neural-network-with-Keras">Creation of the neural network with Keras<a class="anchor-link" href="#Creation-of-the-neural-network-with-Keras">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After importing the necessary tools from Keras, we create the neural network in the following code snippet.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras</span> <span class="k">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">Model</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">,</span> <span class="n">regularizers</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># create the input layer</span>
<span class="c1"># </span>
<span class="c1"># we specify that the input layer </span>
<span class="c1"># should have 64 neurons, one for each pixel</span>
<span class="c1"># in our images. </span>
<span class="c1"># The input neurons do nothing, they </span>
<span class="c1"># just transfer the value at each pixel </span>
<span class="c1"># to the next layer. </span>
<span class="n">img_input</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,))</span>

<span class="c1"># create the hidden layer</span>
<span class="c1">#</span>
<span class="c1"># This layer is a Dense layer, which means</span>
<span class="c1"># that its neurons are fully connected to the </span>
<span class="c1"># neurons in the previous layer (the input layer)</span>
<span class="c1"># We will talk about the activation in a future post</span>
<span class="n">tmp</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> 
                   <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)(</span><span class="n">img_input</span><span class="p">)</span>

<span class="c1"># create the output layer</span>
<span class="c1"># </span>
<span class="c1"># The output layer is another Dense layer.</span>
<span class="c1"># It must have 10 neurons, corresponding to </span>
<span class="c1"># the 10 digit categories </span>
<span class="n">output</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> 
                      <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">tmp</span><span class="p">)</span>

<span class="c1"># create the neural network from the layers</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">img_input</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>

<span class="c1"># print a summary of the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="c1"># =================================================</span>
<span class="c1"># Please don&#39;t pay attention to what follows, </span>
<span class="c1"># we&#39;ll talk about regularization later!</span>
<span class="c1"># For now, it is enough to know that regularization</span>
<span class="c1"># helps the neural network converge properly. </span>
<span class="c1"># I&#39;ve added this regularization because it is </span>
<span class="c1"># performed by default in scikit-learn, </span>
<span class="c1"># and because we want to be able to compare the </span>
<span class="c1"># results of scikit-learn and keras. </span>
<span class="n">l2_rate</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;kernel_regularizer&#39;</span><span class="p">):</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">l2_rate</span><span class="p">)</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">bias_regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">l2_rate</span><span class="p">)</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">activity_regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">l2_rate</span><span class="p">)</span>
<span class="c1"># =================================================</span>

<span class="c1"># define how the neural network will learn, </span>
<span class="c1"># and compile the model. </span>
<span class="c1"># models must be compiled before </span>
<span class="c1"># they can be trained and used. </span>
<span class="c1"># the loss, optimizer, and metrics arguments </span>
<span class="c1"># will be covered in a future post. </span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 64)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 15)                975       
_________________________________________________________________
dense_2 (Dense)              (None, 10)                160       
=================================================================
Total params: 1,135
Trainable params: 1,135
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, we can train the network:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">),</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 1000 samples, validate on 797 samples
Epoch 1/50
1000/1000 [==============================] - 0s 283us/step - loss: 2.1862 - accuracy: 0.2820 - val_loss: 1.8762 - val_accuracy: 0.4015
Epoch 2/50
1000/1000 [==============================] - 0s 25us/step - loss: 1.6556 - accuracy: 0.6000 - val_loss: 1.4465 - val_accuracy: 0.7026
Epoch 3/50
1000/1000 [==============================] - 0s 26us/step - loss: 1.2358 - accuracy: 0.7790 - val_loss: 1.1519 - val_accuracy: 0.7679
Epoch 4/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.9043 - accuracy: 0.8770 - val_loss: 0.8860 - val_accuracy: 0.8206
Epoch 5/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.6885 - accuracy: 0.9010 - val_loss: 0.7609 - val_accuracy: 0.8018
Epoch 6/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.5315 - accuracy: 0.9280 - val_loss: 0.6154 - val_accuracy: 0.8394
Epoch 7/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.4212 - accuracy: 0.9400 - val_loss: 0.5249 - val_accuracy: 0.8871
Epoch 8/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.3538 - accuracy: 0.9510 - val_loss: 0.4787 - val_accuracy: 0.8921
Epoch 9/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.3084 - accuracy: 0.9600 - val_loss: 0.4634 - val_accuracy: 0.8871
Epoch 10/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.2661 - accuracy: 0.9670 - val_loss: 0.4100 - val_accuracy: 0.9009
Epoch 11/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.2312 - accuracy: 0.9720 - val_loss: 0.4087 - val_accuracy: 0.8934
Epoch 12/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.2242 - accuracy: 0.9670 - val_loss: 0.3919 - val_accuracy: 0.8934
Epoch 13/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.2066 - accuracy: 0.9760 - val_loss: 0.3984 - val_accuracy: 0.8971
Epoch 14/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.2050 - accuracy: 0.9690 - val_loss: 0.3984 - val_accuracy: 0.8821
Epoch 15/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.1746 - accuracy: 0.9780 - val_loss: 0.3441 - val_accuracy: 0.9059
Epoch 16/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.1679 - accuracy: 0.9710 - val_loss: 0.3455 - val_accuracy: 0.9109
Epoch 17/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.1613 - accuracy: 0.9830 - val_loss: 0.3565 - val_accuracy: 0.9122
Epoch 18/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.1563 - accuracy: 0.9750 - val_loss: 0.3565 - val_accuracy: 0.8971
Epoch 19/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.1552 - accuracy: 0.9700 - val_loss: 0.3898 - val_accuracy: 0.8959
Epoch 20/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.1482 - accuracy: 0.9750 - val_loss: 0.3995 - val_accuracy: 0.8770
Epoch 21/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.1519 - accuracy: 0.9690 - val_loss: 0.3622 - val_accuracy: 0.9059
Epoch 22/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.1346 - accuracy: 0.9800 - val_loss: 0.3411 - val_accuracy: 0.9034
Epoch 23/50
1000/1000 [==============================] - 0s 28us/step - loss: 0.1132 - accuracy: 0.9820 - val_loss: 0.3080 - val_accuracy: 0.9134
Epoch 24/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.1297 - accuracy: 0.9800 - val_loss: 0.3498 - val_accuracy: 0.8934
Epoch 25/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.1612 - accuracy: 0.9700 - val_loss: 0.4304 - val_accuracy: 0.8808
Epoch 26/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.1653 - accuracy: 0.9720 - val_loss: 0.3841 - val_accuracy: 0.9072
Epoch 27/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.1471 - accuracy: 0.9660 - val_loss: 0.3872 - val_accuracy: 0.8858
Epoch 28/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.1366 - accuracy: 0.9740 - val_loss: 0.3660 - val_accuracy: 0.8883
Epoch 29/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.1240 - accuracy: 0.9800 - val_loss: 0.3663 - val_accuracy: 0.8971
Epoch 30/50
1000/1000 [==============================] - 0s 26us/step - loss: 0.1292 - accuracy: 0.9700 - val_loss: 0.4119 - val_accuracy: 0.8846
Epoch 31/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.1626 - accuracy: 0.9630 - val_loss: 0.3900 - val_accuracy: 0.9021
Epoch 32/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.1139 - accuracy: 0.9760 - val_loss: 0.3730 - val_accuracy: 0.8984
Epoch 33/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.1030 - accuracy: 0.9800 - val_loss: 0.3669 - val_accuracy: 0.8959
Epoch 34/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.0902 - accuracy: 0.9840 - val_loss: 0.3442 - val_accuracy: 0.8996
Epoch 35/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.0775 - accuracy: 0.9890 - val_loss: 0.3692 - val_accuracy: 0.9009
Epoch 36/50
1000/1000 [==============================] - 0s 22us/step - loss: 0.0778 - accuracy: 0.9860 - val_loss: 0.3224 - val_accuracy: 0.9097
Epoch 37/50
1000/1000 [==============================] - 0s 26us/step - loss: 0.0711 - accuracy: 0.9900 - val_loss: 0.3425 - val_accuracy: 0.9084
Epoch 38/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.0692 - accuracy: 0.9870 - val_loss: 0.3195 - val_accuracy: 0.9084
Epoch 39/50
1000/1000 [==============================] - 0s 22us/step - loss: 0.0691 - accuracy: 0.9880 - val_loss: 0.3388 - val_accuracy: 0.9084
Epoch 40/50
1000/1000 [==============================] - 0s 21us/step - loss: 0.0612 - accuracy: 0.9920 - val_loss: 0.3140 - val_accuracy: 0.9172
Epoch 41/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.0569 - accuracy: 0.9910 - val_loss: 0.3351 - val_accuracy: 0.9122
Epoch 42/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.0550 - accuracy: 0.9930 - val_loss: 0.3231 - val_accuracy: 0.9109
Epoch 43/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.0514 - accuracy: 0.9950 - val_loss: 0.3354 - val_accuracy: 0.9122
Epoch 44/50
1000/1000 [==============================] - 0s 22us/step - loss: 0.0490 - accuracy: 0.9950 - val_loss: 0.3315 - val_accuracy: 0.9059
Epoch 45/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.0456 - accuracy: 0.9950 - val_loss: 0.3375 - val_accuracy: 0.9147
Epoch 46/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.0477 - accuracy: 0.9940 - val_loss: 0.3397 - val_accuracy: 0.9046
Epoch 47/50
1000/1000 [==============================] - 0s 22us/step - loss: 0.0495 - accuracy: 0.9940 - val_loss: 0.3277 - val_accuracy: 0.9034
Epoch 48/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.0478 - accuracy: 0.9930 - val_loss: 0.3320 - val_accuracy: 0.9072
Epoch 49/50
1000/1000 [==============================] - 0s 22us/step - loss: 0.0494 - accuracy: 0.9910 - val_loss: 0.3373 - val_accuracy: 0.9046
Epoch 50/50
1000/1000 [==============================] - 0s 22us/step - loss: 0.0494 - accuracy: 0.9890 - val_loss: 0.3832 - val_accuracy: 0.9009
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluating-the-performance">Evaluating the performance<a class="anchor-link" href="#Evaluating-the-performance">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The predictions from the neural network are evaluated for all examples in the test sample by doing</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[1.5537975e-03 5.0299516e-04 5.8268331e-05 5.6680041e-05 5.2190635e-06
 9.9738103e-01 9.8017254e-06 6.1042505e-05 6.5072112e-05 3.0611001e-04]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For each sample, the prediction is an array of 10 values. Each value is the estimated probability for the image to belong to this category.</p>
<p>The predicted category is the one with the largest probability.</p>
<p>Let's write a small function to plot a given image, and to print the true and predicted categories:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">plot_prediction</span><span class="p">(</span><span class="n">index</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predicted probabilities:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predicted category&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">index</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;true probabilities:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;true category&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">index</span><span class="p">]))</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">x_test</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this function, we obtain the category with <code>np.argmax</code> that, for an array, returns the index corresponding to the largest value.</p>
<p>Let's use this function to have a look at a few examples (just choose a different index to look at another example).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_prediction</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>predicted probabilities:
[1.5537975e-03 5.0299516e-04 5.8268331e-05 5.6680041e-05 5.2190635e-06
 9.9738103e-01 9.8017254e-06 6.1042505e-05 6.5072112e-05 3.0611001e-04]
predicted category 5
true probabilities:
[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
true category 5
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, let's compute the accuracy score, which is the probability to classify the digits correctly.</p>
<p>We will compute the accuracy for the test sample, which has not been used to train the network. Again, we will use <code>np.argmax</code> to get the predicted and true categories for each example.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># the second argument of argmax specifies</span>
<span class="c1"># that we want to get argmax for each example. </span>
<span class="c1"># without this argument, argmax would return </span>
<span class="c1"># the largest value in the whole array,</span>
<span class="c1"># considering all examples</span>
<span class="n">y_test_best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_test_best</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">predictions_best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">accuracy_score</span>
<span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_best</span><span class="p">,</span> <span class="n">predictions_best</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(797,)
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[12]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9008782936010038</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You should obtain an accuracy around 90%, similar to the one we had obtained in the same conditions with scikit-learn.</p>
<p>Please note that the result is not deterministic, so the accuracy will vary every time you train the network. I usually get an accuracy between 90 and 93%, but I sometimes get a value as low as 87%.</p>
<p>Please repeat the exercise starting from the creation of the neural network to see what happens.</p>
<h2 id="What-next?">What next?<a class="anchor-link" href="#What-next?">&#182;</a></h2><p>In this post, you have trained your first neural network with keras.</p>
<p>Keras is the easiest and most powerful way to work with neural networks, and we will use it very often on this blog.</p>
<p>Very soon, we'll start to do deep learning on a GPU with keras and TensorFlow.</p>
<p>More information: <a href="https://keras.io/getting-started/sequential-model-guide/">Guide to the sequential model of keras</a></p>

</div>
</div>
</div>
 

