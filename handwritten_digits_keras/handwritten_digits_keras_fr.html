<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#192;-propos-de-ce-tutoriel">&#192; propos de ce tutoriel<a class="anchor-link" href="#&#192;-propos-de-ce-tutoriel">&#182;</a></h2><p>Dans mon article sur la <a href="https://thedatafrog.com/fr/reconnaissance-decriture-manuscrite-scikit-learn/">reconnaissance de chiffres manuscrits avec scikit-learn</a>, nous avons vu qu'avec <a href="https://scikit-learn.org">scikit-learn</a>, il est facile d'entraîner un réseau de neurones simple. Nous avons réussi à reconnaître des images de chiffres avec une précision supérieure à 90%.</p>
<p>Malheureusement, scikit-learn n'est généralement pas adapté aux réseaux de neurones.</p>
<p>Son but est en fait de fournir une interface unifiée pour l'entraînement et le test de différents algorithmes de machine learning: réseaux de neurones bien sûr, mais aussi SVM, Bayes, plus proches voisins, arbres de décision, etc.</p>
<p>En effet, dans un projet de machine learning, on passe une bonne partie de son temps à choisir le bon algorithme et à l'optimiser. Scikit-learn a été conçu pour rendre ces tâches aussi simples et rapides que possible.</p>
<p>Par contre, pour ce qui est des réseaux de neurones:</p>
<ul>
<li>son interface ne permet pas de créer de réseaux complexes, ni de contrôler leur fonctionnement dans les détails </li>
<li>il n'est pas adapté au <a href="https://thedatafrog.com/install-tensorflow-windows/">deep learning</a></li>
</ul>
<p>Dans cet article, nous allons répéter notre exercice sur la reconnaissance de chiffres manuscrits, en utilisant cette fois <a href="https://keras.io/">Keras</a>, un package spécialisé dans les réseaux de neurones.</p>
<p>Vous apprendrez à:</p>
<ul>
<li>Installer Keras</li>
<li>Créer un réseau de neurones simple avec cet outil</li>
<li>Estimer les performances de ce réseau</li>
</ul>
<p>À l'avenir, nous utiliserons Keras comme interface vers TensorFlow pour faire du deep learning.</p>
<p><strong>Prérequis:</strong></p>
<p>Il faudrait que vous ayez déjà manipulé un réseau de neurones simple et que vous ayez quelques notions de:</p>
<ul>
<li>numpy, </li>
<li>matplotlib, </li>
<li>jupyter notebook</li>
</ul>
<p>Si ce n'est pas le cas, le tuto sur la <a href="https://thedatafrog.com/fr/reconnaissance-decriture-manuscrite-scikit-learn/">reconnaissance de chiffres manuscrits avec scikit-learn</a> est fait pour vous!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Installation">Installation<a class="anchor-link" href="#Installation">&#182;</a></h2><p>Installez d'abord <a href="https://www.anaconda.com/download/">Anaconda</a> si ce n'est pas encore fait.</p>
<p>Lancez l'application Anaconda Navigator.</p>
<p>Dans l'onglet Environments, sélectionnez l'environnement de base (root), 
et installez-y le package keras. Anaconda peut mettre plusieurs minutes à installer ce package, soyez patient.</p>
<p>Ensuite, allez dans l'onglet Home pour lancer jupyter notebook.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Enfin, récupérez ce notebook, et ouvrez-le dans jupyter notebook.</p>
<ul>
<li><a href="https://github.com/cbernet/maldives/archive/master.zip">téléchargez le dépôt contenant ce notebook</a></li>
<li>décompressez-le, par exemple dans <code>Downloads/maldives-master</code></li>
<li>dans jupyter notebook, naviguez vers <code>Downloads/maldives-master/handwritten_digits_keras</code></li>
<li>ouvrez <code>handwritten_digits_keras_fr.ipynb</code></li>
</ul>
<p>Cette page devrait apparaître dans le notebook. À partir de maintenant, vous pouvez suivre ce tutoriel dans le notebook.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Pr&#233;paration-de-l'&#233;chantillon-de-donn&#233;es">Pr&#233;paration de l'&#233;chantillon de donn&#233;es<a class="anchor-link" href="#Pr&#233;paration-de-l'&#233;chantillon-de-donn&#233;es">&#182;</a></h2><p>Comme dans <a href="https://thedatafrog.com/fr/reconnaissance-decriture-manuscrite-scikit-learn/">reconnaissance de chiffres manuscrits avec scikit-learn</a>, nous allons utiliser l'échantillon de chiffres fourni avec scikit-learn. Les chiffres sont des images 8x8, et nous allons les traiter avec un réseau de neurones avec:</p>
<ul>
<li>une couche d'entrée avec 8x8 = 64 neurones </li>
<li>une couche cachée de 15 neurones </li>
<li>une couche de sortie de 10 neurones, correspondant aux dix catégories de chiffres. </li>
</ul>
<p>D'abord, initialisons nos outils et chargeons l'échantillon:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">os</span> 
<span class="c1"># for some reason, the following </span>
<span class="c1"># is needed to run on mac os X</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;KMP_DUPLICATE_LIB_OK&#39;</span><span class="p">]</span><span class="o">=</span><span class="s1">&#39;True&#39;</span>  

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">datasets</span>
<span class="n">digits</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_digits</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>La couche d'entrée requiert un tableau 1D de 64 valeurs, mais nos images sont 2D, avec 8x8 pixels. Nous devons donc les sérialiser:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">x</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[2]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(1797, 64)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>De plus, un peu de travail est nécessaire avant de pouvoir utiliser les étiquettes.</p>
<p>Pour l'instant, <code>digits.target</code> contient le chiffre auquel correspond chaque image dans l'échantillon:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">digits</span><span class="o">.</span><span class="n">target</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[3]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([0, 1, 2, ..., 8, 9, 8])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Mais avec Keras, nous devons construire un réseau avec 10 neurones de sortie. C'est aussi le cas avec scikit-learn, bien que ce soit caché à l'utilisateur. Au cours de l'entraînement, Keras devra comparer les 10 valeurs de sortie de ces neurones à l'étiquette pour donner un retour au réseau et lui permettre de s'améliorer. Mais comment pouvons nous comparer un tableau de 10 valeurs à une seule valeur, celle de l'étiquette?</p>
<p>La solution est de traduire chaque étiquette en un tableau de taille 10 (une technique appelée <em>one-hot encoding</em>):</p>
<ul>
<li>la valeur <code>0</code> donne <code>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</code></li>
<li><code>1</code> donne <code>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</code></li>
<li>...</li>
<li><code>9</code> donne <code>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</code></li>
</ul>
<p>Après cela, les valeurs des 10 neurones de sortie, qui sont des probabilités entre 0 et 1, peuvent être directement comparées aux 10 valeurs de l'étiquette.</p>
<p>De cette façon, pour un chiffre donné, par exemple 0, le réseau de neurones sera entraîné à donner une probabilité élevée sur le premier neurone de sortie, et une faible probabilité sur les neurones suivants.</p>
<p>Cet encodage se fait facilement avec les outils fournis par Keras:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.utils</span> <span class="k">import</span> <span class="n">np_utils</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np_utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[0 1 2 ... 8 9 8]
[[1. 0. 0. ... 0. 0. 0.]
 [0. 1. 0. ... 0. 0. 0.]
 [0. 0. 1. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 1. 0.]
 [0. 0. 0. ... 0. 0. 1.]
 [0. 0. 0. ... 0. 1. 0.]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Nous pouvons maintenant partager nos données entre un échantillon d'entraînement et un échantillon de test:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">split_limit</span><span class="o">=</span><span class="mi">1000</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="n">split_limit</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">split_limit</span><span class="p">]</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">split_limit</span><span class="p">:]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">split_limit</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Les 1000 premières images et étiquettes seront utilisées pour l'entraînement, et les suivantes pour l'évaluation des performances de notre réseau.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Cr&#233;ation-du-r&#233;seau-de-neurones-avec-Keras">Cr&#233;ation du r&#233;seau de neurones avec Keras<a class="anchor-link" href="#Cr&#233;ation-du-r&#233;seau-de-neurones-avec-Keras">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Après avoir importé les outils nécessaires, créons le réseau de neurones.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras</span> <span class="k">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">Model</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">,</span> <span class="n">regularizers</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Création de la couche d&#39;entrée</span>
<span class="c1"># </span>
<span class="c1"># On spécifie que cette couche doit </span>
<span class="c1"># avoir 64 neurones, un pour chaque </span>
<span class="c1"># pixel dans nos images. </span>
<span class="c1"># Les neurones d&#39;entrée ne font rien, </span>
<span class="c1"># ils se contentent de transférer la </span>
<span class="c1"># valeur sur chaque pixel à la couche </span>
<span class="c1"># suivante.</span>
<span class="n">img_input</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,))</span>


<span class="c1"># Création de la couche cachée</span>
<span class="c1">#</span>
<span class="c1"># Cette couche est dense, ce qui veut </span>
<span class="c1"># dire que chacun de ses neurones est </span>
<span class="c1"># connecté à tous les neurones de la </span>
<span class="c1"># couche précédente (la couche d&#39;entrée).</span>
<span class="c1"># Nous parlerons de l&#39;activation dans un</span>
<span class="c1"># futur post.</span>
<span class="n">tmp</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> 
                   <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)(</span><span class="n">img_input</span><span class="p">)</span>

<span class="c1"># Création de la couche de sortie</span>
<span class="c1"># </span>
<span class="c1"># La couche de sortie est dense également. </span>
<span class="c1"># Elle doit avoir 10 neurones, correspondant</span>
<span class="c1"># aux 10 catégories de chiffres. </span>
<span class="n">output</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> 
                      <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">tmp</span><span class="p">)</span>

<span class="c1"># Création du réseau de neurones </span>
<span class="c1"># à partir des couches</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">img_input</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>

<span class="c1"># Impression d&#39;une description du réseau</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="c1"># =================================================</span>
<span class="c1"># Merci de pas prêter attention à cette partie. </span>
<span class="c1"># Nous parlerons de la régularisation plus tard.</span>
<span class="c1"># Pour l&#39;instant, il suffit de noter que la </span>
<span class="c1"># régularisation aide le réseau à converger </span>
<span class="c1"># correctement. </span>
<span class="c1"># J&#39;ai rajouté cette régularisation ici car elle </span>
<span class="c1"># est effectuée par défaut dans scikit-learn,  </span>
<span class="c1"># et que nous voulons pouvoir comparer les résultats</span>
<span class="c1"># de keras et scikit-learn. </span>
<span class="n">l2_rate</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;kernel_regularizer&#39;</span><span class="p">):</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">l2_rate</span><span class="p">)</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">bias_regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">l2_rate</span><span class="p">)</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">activity_regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">l2_rate</span><span class="p">)</span>
<span class="c1"># =================================================</span>

<span class="c1"># Définition de la méthode d&#39;apprentissage, </span>
<span class="c1"># et compilation du modèle.</span>
<span class="c1"># </span>
<span class="c1"># Le modèle doit être compilé pour être </span>
<span class="c1"># entraîné et utilisé. </span>
<span class="c1"># Les arguments loss, optimizer, et metric</span>
<span class="c1"># seront couverts dans un futur post. </span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;model_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 64)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 15)                975       
_________________________________________________________________
dense_2 (Dense)              (None, 10)                160       
=================================================================
Total params: 1,135
Trainable params: 1,135
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finalement, nous pouvons entraîner le réseau:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">),</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 1000 samples, validate on 797 samples
Epoch 1/50
1000/1000 [==============================] - 0s 397us/step - loss: 2.1134 - accuracy: 0.2210 - val_loss: 1.7801 - val_accuracy: 0.5144
Epoch 2/50
1000/1000 [==============================] - 0s 25us/step - loss: 1.5518 - accuracy: 0.6310 - val_loss: 1.3405 - val_accuracy: 0.6838
Epoch 3/50
1000/1000 [==============================] - 0s 25us/step - loss: 1.0895 - accuracy: 0.8280 - val_loss: 0.9646 - val_accuracy: 0.8369
Epoch 4/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.7730 - accuracy: 0.8940 - val_loss: 0.6991 - val_accuracy: 0.8783
Epoch 5/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.5380 - accuracy: 0.9200 - val_loss: 0.5841 - val_accuracy: 0.8883
Epoch 6/50
1000/1000 [==============================] - 0s 26us/step - loss: 0.4211 - accuracy: 0.9280 - val_loss: 0.5142 - val_accuracy: 0.8846
Epoch 7/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.3359 - accuracy: 0.9490 - val_loss: 0.4503 - val_accuracy: 0.8996
Epoch 8/50
1000/1000 [==============================] - 0s 28us/step - loss: 0.2813 - accuracy: 0.9490 - val_loss: 0.4092 - val_accuracy: 0.8971
Epoch 9/50
1000/1000 [==============================] - 0s 27us/step - loss: 0.2436 - accuracy: 0.9600 - val_loss: 0.3884 - val_accuracy: 0.9046
Epoch 10/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.2001 - accuracy: 0.9720 - val_loss: 0.3862 - val_accuracy: 0.9072
Epoch 11/50
1000/1000 [==============================] - 0s 29us/step - loss: 0.1715 - accuracy: 0.9800 - val_loss: 0.3711 - val_accuracy: 0.8984
Epoch 12/50
1000/1000 [==============================] - 0s 26us/step - loss: 0.1630 - accuracy: 0.9760 - val_loss: 0.3590 - val_accuracy: 0.9021
Epoch 13/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.1493 - accuracy: 0.9790 - val_loss: 0.3427 - val_accuracy: 0.9034
Epoch 14/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.1417 - accuracy: 0.9840 - val_loss: 0.3611 - val_accuracy: 0.9046
Epoch 15/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.1282 - accuracy: 0.9870 - val_loss: 0.3388 - val_accuracy: 0.8996
Epoch 16/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.1126 - accuracy: 0.9890 - val_loss: 0.3430 - val_accuracy: 0.8959
Epoch 17/50
1000/1000 [==============================] - 0s 26us/step - loss: 0.1049 - accuracy: 0.9890 - val_loss: 0.3468 - val_accuracy: 0.8959
Epoch 18/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.0970 - accuracy: 0.9920 - val_loss: 0.3240 - val_accuracy: 0.9122
Epoch 19/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.0937 - accuracy: 0.9890 - val_loss: 0.3059 - val_accuracy: 0.9059
Epoch 20/50
1000/1000 [==============================] - 0s 26us/step - loss: 0.0834 - accuracy: 0.9950 - val_loss: 0.3067 - val_accuracy: 0.9072
Epoch 21/50
1000/1000 [==============================] - 0s 26us/step - loss: 0.0815 - accuracy: 0.9940 - val_loss: 0.3240 - val_accuracy: 0.9072
Epoch 22/50
1000/1000 [==============================] - 0s 31us/step - loss: 0.0866 - accuracy: 0.9930 - val_loss: 0.3348 - val_accuracy: 0.9034
Epoch 23/50
1000/1000 [==============================] - 0s 29us/step - loss: 0.0861 - accuracy: 0.9930 - val_loss: 0.3379 - val_accuracy: 0.8984
Epoch 24/50
1000/1000 [==============================] - 0s 27us/step - loss: 0.0821 - accuracy: 0.9890 - val_loss: 0.3091 - val_accuracy: 0.9059
Epoch 25/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.0710 - accuracy: 0.9940 - val_loss: 0.3208 - val_accuracy: 0.9072
Epoch 26/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.0623 - accuracy: 0.9960 - val_loss: 0.3216 - val_accuracy: 0.9034
Epoch 27/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.0606 - accuracy: 0.9950 - val_loss: 0.3244 - val_accuracy: 0.9021
Epoch 28/50
1000/1000 [==============================] - 0s 25us/step - loss: 0.0563 - accuracy: 0.9960 - val_loss: 0.3217 - val_accuracy: 0.9059
Epoch 29/50
1000/1000 [==============================] - 0s 26us/step - loss: 0.0538 - accuracy: 0.9970 - val_loss: 0.3172 - val_accuracy: 0.9046
Epoch 30/50
1000/1000 [==============================] - 0s 26us/step - loss: 0.0511 - accuracy: 0.9960 - val_loss: 0.3208 - val_accuracy: 0.8996
Epoch 31/50
1000/1000 [==============================] - 0s 27us/step - loss: 0.0493 - accuracy: 0.9970 - val_loss: 0.3155 - val_accuracy: 0.9021
Epoch 32/50
1000/1000 [==============================] - 0s 27us/step - loss: 0.0466 - accuracy: 0.9970 - val_loss: 0.3138 - val_accuracy: 0.9009
Epoch 33/50
1000/1000 [==============================] - 0s 26us/step - loss: 0.0444 - accuracy: 0.9970 - val_loss: 0.3192 - val_accuracy: 0.8971
Epoch 34/50
1000/1000 [==============================] - 0s 29us/step - loss: 0.0432 - accuracy: 0.9970 - val_loss: 0.3185 - val_accuracy: 0.9009
Epoch 35/50
1000/1000 [==============================] - 0s 32us/step - loss: 0.0419 - accuracy: 0.9970 - val_loss: 0.3191 - val_accuracy: 0.9009
Epoch 36/50
1000/1000 [==============================] - 0s 30us/step - loss: 0.0405 - accuracy: 0.9970 - val_loss: 0.3177 - val_accuracy: 0.8971
Epoch 37/50
1000/1000 [==============================] - 0s 26us/step - loss: 0.0396 - accuracy: 0.9970 - val_loss: 0.3198 - val_accuracy: 0.8996
Epoch 38/50
1000/1000 [==============================] - 0s 26us/step - loss: 0.0384 - accuracy: 0.9970 - val_loss: 0.3179 - val_accuracy: 0.8984
Epoch 39/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.0378 - accuracy: 0.9970 - val_loss: 0.3199 - val_accuracy: 0.9009
Epoch 40/50
1000/1000 [==============================] - 0s 24us/step - loss: 0.0369 - accuracy: 0.9970 - val_loss: 0.3224 - val_accuracy: 0.8971
Epoch 41/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.0357 - accuracy: 0.9970 - val_loss: 0.3223 - val_accuracy: 0.8984
Epoch 42/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.0352 - accuracy: 0.9970 - val_loss: 0.3256 - val_accuracy: 0.8971
Epoch 43/50
1000/1000 [==============================] - 0s 22us/step - loss: 0.0346 - accuracy: 0.9970 - val_loss: 0.3218 - val_accuracy: 0.8996
Epoch 44/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.0337 - accuracy: 0.9970 - val_loss: 0.3236 - val_accuracy: 0.8971
Epoch 45/50
1000/1000 [==============================] - 0s 22us/step - loss: 0.0332 - accuracy: 0.9970 - val_loss: 0.3191 - val_accuracy: 0.9009
Epoch 46/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.0324 - accuracy: 0.9970 - val_loss: 0.3235 - val_accuracy: 0.8984
Epoch 47/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.0321 - accuracy: 0.9970 - val_loss: 0.3240 - val_accuracy: 0.8984
Epoch 48/50
1000/1000 [==============================] - 0s 22us/step - loss: 0.0322 - accuracy: 0.9960 - val_loss: 0.3266 - val_accuracy: 0.8984
Epoch 49/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.0312 - accuracy: 0.9970 - val_loss: 0.3223 - val_accuracy: 0.9021
Epoch 50/50
1000/1000 [==============================] - 0s 23us/step - loss: 0.0308 - accuracy: 0.9980 - val_loss: 0.3260 - val_accuracy: 0.8971
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#201;valuation-des-performances">&#201;valuation des performances<a class="anchor-link" href="#&#201;valuation-des-performances">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Les prédictions du réseau de neurones sont évaluées pour tous les exemples de l'échantillon de test:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[4.6237273e-04 2.6946730e-04 7.0270261e-04 1.0361271e-03 6.8260713e-05
 9.9545693e-01 4.7021132e-04 8.3707950e-05 1.3659039e-03 8.4294996e-05]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Pour chaque exemple, la prédiction est un tableau de 10 valeurs. Chaque valeur est la probabilité, estimée par le réseau, que l'image appartienne à une catégorie donnée.</p>
<p>La catégorie prédite est celle avec la probabilité la plus grande.</p>
<p>Écrivons maintenant une petite fonction pour afficher une image donnée, et imprimer la catégorie prédite ainsi que la catégorie réelle:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">plot_prediction</span><span class="p">(</span><span class="n">index</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predicted probabilities:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predicted category&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">index</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;true probabilities:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;true category&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">index</span><span class="p">]))</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">x_test</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Dans cette fonction, on obtient la catégorie avec <code>np.argmax</code> qui, pour un tableau, retourne l'index correspondant à la valeur maximum.</p>
<p>Utilisons cette fonction pour regarder quelques exemples (changez juste l'index pour choisir un autre exemple):</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_prediction</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>predicted probabilities:
[4.6237273e-04 2.6946730e-04 7.0270261e-04 1.0361271e-03 6.8260713e-05
 9.9545693e-01 4.7021132e-04 8.3707950e-05 1.3659039e-03 8.4294996e-05]
predicted category 5
true probabilities:
[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
true category 5
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Enfin, calculons la précision, c'est à dire la probabilité de classer les chiffres correctement.</p>
<p>On calcule cette précision sur l'échantillon de test, qui n'a pas été utilisé dans l'entraînement du réseau. À nouveau, on utilise <code>np.argmax</code> pour obtenir les catégories vraies et prédites pour chaque exemple.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Le deuxième argument de argmax spécifie</span>
<span class="c1"># que l&#39;on souhaite conserver la première </span>
<span class="c1"># dimension du tableau. </span>
<span class="c1"># Ainsi, argmax est calculé pour chaque </span>
<span class="c1"># exemple. </span>
<span class="c1"># Sans cet argument, argmax retournerait</span>
<span class="c1"># une seule valeur, la probabilité maximum </span>
<span class="c1"># dans le tableau complet, </span>
<span class="c1"># en considérant l&#39;ensemble des exemples </span>
<span class="n">y_test_best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_test_best</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">predictions_best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">accuracy_score</span>
<span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_best</span><span class="p">,</span> <span class="n">predictions_best</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(797,)
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[14]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.8971141781681304</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Vous devriez obtenir une précision autour de 91%, similaire à celle que nous avons obtenue dans les mêmes conditions avec scikit-learn.</p>
<p>Le résultat n'est pas reproductible, et la précision variera à chaque fois que vous ré-entraînerez un nouveau réseau. Personnellement, j'obtiens généralement une précision entre 90 et 93%.</p>
<p>Et pour vous, que se passe-t'il lorsque vous répétez l'exercice?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Et-ensuite?">Et ensuite?<a class="anchor-link" href="#Et-ensuite?">&#182;</a></h2><p>Dans ce post, vous avez entraîné votre premier réseau de neurones avec keras.</p>
<p>Keras est un outil incontournable, et nous l'utiliserons régulièrement sur ce blog.</p>
<p>Très bientôt, nous nous lancerons dans le deep learning sur GPU avec keras et TensorFlow.</p>
<p>Pour en savoir plus: <a href="https://keras.io/getting-started/sequential-model-guide/">Guide to the sequential model of keras</a></p>

</div>
</div>
</div>
 

