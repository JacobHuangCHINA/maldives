{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation de l'échantillon de données\n",
    "\n",
    "Comme dans [reconnaissance de chiffres manuscrits avec scikit-learn](https://thedatafrog.com/fr/handwritten-digit-recognition-scikit-learn/), nous allons utiliser l'échantillon de chiffres fourni avec scikit-learn. Les chiffres sont des images 8x8, et nous allons les traiter avec un réseau de neurones avec: \n",
    "\n",
    "* une couche d'entrée avec 8x8 = 64 neurones \n",
    "* une couche cachée de 15 neurones \n",
    "* une couche de sortie de 10 neurones, correspondant aux dix catégories de chiffres. \n",
    "\n",
    "D'abord, initialisons nos outils et chargeons l'échantillon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "# for some reason, the following \n",
    "# is needed to run on mac os X\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'  \n",
    "\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La couche d'entrée requiert un tableau 1D de 64 valeurs, mais nos images sont 2D, avec 8x8 pixels. Nous devons donc les sérialiser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = digits.images.reshape((len(digits.images), -1))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, un peu de travail est nécessaire avant de pouvoir utiliser les étiquettes. \n",
    "\n",
    "Pour l'instant, `digits.target` contient le chiffre auquel correspond chaque image dans l'échantillon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais avec Keras, nous devons construire un réseau avec 10 neurones de sortie. C'est aussi le cas avec scikit-learn, bien que ce soit caché à l'utilisateur. Au cours de l'entraînement, Keras devra comparer les 10 valeurs de sortie de ces neurones à l'étiquette pour donner un retour au réseau et lui permettre de s'améliorer. Mais comment pouvons nous comparer un tableau de 10 valeurs à une seule valeur, celle de l'étiquette?\n",
    "\n",
    "La solution est de traduire chaque étiquette en un tableau de taille 10 (une technique appelée *one-hot encoding*): \n",
    "\n",
    "* la valeur `0` donne `[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]`\n",
    "* `1` donne `[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]`\n",
    "* ...\n",
    "* `9` donne `[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]`\n",
    "\n",
    "Après cela, les valeurs des 10 neurones de sortie, qui sont des probabilités entre 0 et 1, peuvent être directement comparées aux 10 valeurs de l'étiquette. \n",
    "\n",
    "De cette façon, pour un chiffre donné, par exemple 0, le réseau de neurones sera entraîné à donner une probabilité élevée sur le premier neurone de sortie, et une faible probabilité sur les neurones suivants. \n",
    "\n",
    "Cet encodage se fait facilement avec les outils fournis par Keras: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "y = np_utils.to_categorical(digits.target,10)\n",
    "print(digits.target)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant partager nos données entre un échantillon d'entraînement et un échantillon de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_limit=1000\n",
    "x_train = x[:split_limit]\n",
    "y_train = y[:split_limit]\n",
    "x_test = x[split_limit:]\n",
    "y_test = y[split_limit:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les 1000 premières images et étiquettes seront utilisées pour l'entraînement, et les suivantes pour l'évaluation des performances de notre réseau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du réseau de neurones avec Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir importé les outils nécessaires, créons le réseau de neurones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, Model, optimizers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                975       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                160       \n",
      "=================================================================\n",
      "Total params: 1,135\n",
      "Trainable params: 1,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Création de la couche d'entrée\n",
    "# \n",
    "# On spécifie que cette couche doit \n",
    "# avoir 64 neurones, un pour chaque \n",
    "# pixel dans nos images. \n",
    "# Les neurones d'entrée ne font rien, \n",
    "# ils se contentent de transférer la \n",
    "# valeur sur chaque pixel à la couche \n",
    "# suivante.\n",
    "img_input = layers.Input(shape=(64,))\n",
    "\n",
    "\n",
    "# Création de la couche cachée\n",
    "#\n",
    "# Cette couche est dense, ce qui veut \n",
    "# dire que chacun de ses neurones est \n",
    "# connecté à tous les neurones de la \n",
    "# couche précédente (la couche d'entrée).\n",
    "# Nous parlerons de l'activation dans un\n",
    "# futur post.\n",
    "tmp = layers.Dense(15, \n",
    "                   activation='sigmoid')(img_input)\n",
    "\n",
    "# Création de la couche de sortie\n",
    "# \n",
    "# La couche de sortie est dense également. \n",
    "# Elle doit avoir 10 neurones, correspondant\n",
    "# aux 10 catégories de chiffres. \n",
    "output = layers.Dense(10, \n",
    "                      activation='softmax')(tmp)\n",
    "\n",
    "# Création du réseau de neurones \n",
    "# à partir des couches\n",
    "model = Model(img_input, output)\n",
    "\n",
    "# Impression d'une description du réseau\n",
    "model.summary()\n",
    "\n",
    "# =================================================\n",
    "# Merci de pas prêter attention à cette partie. \n",
    "# Nous parlerons de la régularisation plus tard.\n",
    "# Pour l'instant, il suffit de noter que la \n",
    "# régularisation aide le réseau à converger \n",
    "# correctement. \n",
    "# J'ai rajouté cette régularisation ici car elle \n",
    "# est effectuée par défaut dans scikit-learn,  \n",
    "# et que nous voulons pouvoir comparer les résultats\n",
    "# de keras et scikit-learn. \n",
    "l2_rate = 1e-4\n",
    "for layer in model.layers:\n",
    "    if hasattr(layer, 'kernel_regularizer'):\n",
    "        layer.kernel_regularizer = regularizers.l2(l2_rate)\n",
    "        layer.bias_regularizer = regularizers.l2(l2_rate)\n",
    "        layer.activity_regularizer = regularizers.l2(l2_rate)\n",
    "# =================================================\n",
    "\n",
    "# Définition de la méthode d'apprentissage, \n",
    "# et compilation du modèle.\n",
    "# \n",
    "# Le modèle doit être compilé pour être \n",
    "# entraîné et utilisé. \n",
    "# Les arguments loss, optimizer, et metric\n",
    "# seront couverts dans un futur post. \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=0.1, momentum=0.9),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, nous pouvons entraîner le réseau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 797 samples\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 0s 397us/step - loss: 2.1134 - accuracy: 0.2210 - val_loss: 1.7801 - val_accuracy: 0.5144\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 1.5518 - accuracy: 0.6310 - val_loss: 1.3405 - val_accuracy: 0.6838\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 1.0895 - accuracy: 0.8280 - val_loss: 0.9646 - val_accuracy: 0.8369\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.7730 - accuracy: 0.8940 - val_loss: 0.6991 - val_accuracy: 0.8783\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.5380 - accuracy: 0.9200 - val_loss: 0.5841 - val_accuracy: 0.8883\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.4211 - accuracy: 0.9280 - val_loss: 0.5142 - val_accuracy: 0.8846\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.3359 - accuracy: 0.9490 - val_loss: 0.4503 - val_accuracy: 0.8996\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.2813 - accuracy: 0.9490 - val_loss: 0.4092 - val_accuracy: 0.8971\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.2436 - accuracy: 0.9600 - val_loss: 0.3884 - val_accuracy: 0.9046\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.2001 - accuracy: 0.9720 - val_loss: 0.3862 - val_accuracy: 0.9072\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1715 - accuracy: 0.9800 - val_loss: 0.3711 - val_accuracy: 0.8984\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1630 - accuracy: 0.9760 - val_loss: 0.3590 - val_accuracy: 0.9021\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.1493 - accuracy: 0.9790 - val_loss: 0.3427 - val_accuracy: 0.9034\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1417 - accuracy: 0.9840 - val_loss: 0.3611 - val_accuracy: 0.9046\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.1282 - accuracy: 0.9870 - val_loss: 0.3388 - val_accuracy: 0.8996\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.1126 - accuracy: 0.9890 - val_loss: 0.3430 - val_accuracy: 0.8959\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1049 - accuracy: 0.9890 - val_loss: 0.3468 - val_accuracy: 0.8959\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0970 - accuracy: 0.9920 - val_loss: 0.3240 - val_accuracy: 0.9122\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0937 - accuracy: 0.9890 - val_loss: 0.3059 - val_accuracy: 0.9059\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0834 - accuracy: 0.9950 - val_loss: 0.3067 - val_accuracy: 0.9072\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0815 - accuracy: 0.9940 - val_loss: 0.3240 - val_accuracy: 0.9072\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0866 - accuracy: 0.9930 - val_loss: 0.3348 - val_accuracy: 0.9034\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0861 - accuracy: 0.9930 - val_loss: 0.3379 - val_accuracy: 0.8984\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0821 - accuracy: 0.9890 - val_loss: 0.3091 - val_accuracy: 0.9059\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0710 - accuracy: 0.9940 - val_loss: 0.3208 - val_accuracy: 0.9072\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0623 - accuracy: 0.9960 - val_loss: 0.3216 - val_accuracy: 0.9034\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0606 - accuracy: 0.9950 - val_loss: 0.3244 - val_accuracy: 0.9021\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0563 - accuracy: 0.9960 - val_loss: 0.3217 - val_accuracy: 0.9059\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0538 - accuracy: 0.9970 - val_loss: 0.3172 - val_accuracy: 0.9046\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0511 - accuracy: 0.9960 - val_loss: 0.3208 - val_accuracy: 0.8996\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0493 - accuracy: 0.9970 - val_loss: 0.3155 - val_accuracy: 0.9021\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0466 - accuracy: 0.9970 - val_loss: 0.3138 - val_accuracy: 0.9009\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0444 - accuracy: 0.9970 - val_loss: 0.3192 - val_accuracy: 0.8971\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0432 - accuracy: 0.9970 - val_loss: 0.3185 - val_accuracy: 0.9009\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0419 - accuracy: 0.9970 - val_loss: 0.3191 - val_accuracy: 0.9009\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0405 - accuracy: 0.9970 - val_loss: 0.3177 - val_accuracy: 0.8971\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0396 - accuracy: 0.9970 - val_loss: 0.3198 - val_accuracy: 0.8996\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0384 - accuracy: 0.9970 - val_loss: 0.3179 - val_accuracy: 0.8984\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0378 - accuracy: 0.9970 - val_loss: 0.3199 - val_accuracy: 0.9009\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0369 - accuracy: 0.9970 - val_loss: 0.3224 - val_accuracy: 0.8971\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0357 - accuracy: 0.9970 - val_loss: 0.3223 - val_accuracy: 0.8984\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0352 - accuracy: 0.9970 - val_loss: 0.3256 - val_accuracy: 0.8971\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0346 - accuracy: 0.9970 - val_loss: 0.3218 - val_accuracy: 0.8996\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0337 - accuracy: 0.9970 - val_loss: 0.3236 - val_accuracy: 0.8971\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0332 - accuracy: 0.9970 - val_loss: 0.3191 - val_accuracy: 0.9009\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0324 - accuracy: 0.9970 - val_loss: 0.3235 - val_accuracy: 0.8984\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0321 - accuracy: 0.9970 - val_loss: 0.3240 - val_accuracy: 0.8984\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0322 - accuracy: 0.9960 - val_loss: 0.3266 - val_accuracy: 0.8984\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0312 - accuracy: 0.9970 - val_loss: 0.3223 - val_accuracy: 0.9021\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0308 - accuracy: 0.9980 - val_loss: 0.3260 - val_accuracy: 0.8971\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=x_train, y=y_train, validation_data=(x_test,y_test),\n",
    "                    batch_size=100, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation des performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les prédictions du réseau de neurones sont évaluées pour tous les exemples de l'échantillon de test: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.6237273e-04 2.6946730e-04 7.0270261e-04 1.0361271e-03 6.8260713e-05\n",
      " 9.9545693e-01 4.7021132e-04 8.3707950e-05 1.3659039e-03 8.4294996e-05]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "print(predictions[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque exemple, la prédiction est un tableau de 10 valeurs. Chaque valeur est la probabilité, estimée par le réseau, que l'image appartienne à une catégorie donnée. \n",
    "\n",
    "La catégorie prédite est celle avec la probabilité la plus grande.  \n",
    "\n",
    "Écrivons maintenant une petite fonction pour afficher une image donnée, et imprimer la catégorie prédite ainsi que la catégorie réelle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(index):\n",
    "    print('predicted probabilities:')\n",
    "    print(predictions[index])\n",
    "    print('predicted category', np.argmax(predictions[index]))\n",
    "    print('true probabilities:')\n",
    "    print(y_test[index])\n",
    "    print('true category', np.argmax(y_test[index]))\n",
    "    img = x_test[index].reshape(8,8)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette fonction, on obtient la catégorie avec `np.argmax` qui, pour un tableau, retourne l'index correspondant à la valeur maximum. \n",
    "\n",
    "Utilisons cette fonction pour regarder quelques exemples (changez juste l'index pour choisir un autre exemple):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted probabilities:\n",
      "[4.6237273e-04 2.6946730e-04 7.0270261e-04 1.0361271e-03 6.8260713e-05\n",
      " 9.9545693e-01 4.7021132e-04 8.3707950e-05 1.3659039e-03 8.4294996e-05]\n",
      "predicted category 5\n",
      "true probabilities:\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "true category 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_prediction(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, calculons la précision, c'est à dire la probabilité de classer les chiffres correctement. \n",
    "\n",
    "On calcule cette précision sur l'échantillon de test, qui n'a pas été utilisé dans l'entraînement du réseau. À nouveau, on utilise `np.argmax` pour obtenir les catégories vraies et prédites pour chaque exemple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(797,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8971141781681304"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Le deuxième argument de argmax spécifie\n",
    "# que l'on souhaite conserver la première \n",
    "# dimension du tableau. \n",
    "# Ainsi, argmax est calculé pour chaque \n",
    "# exemple. \n",
    "# Sans cet argument, argmax retournerait\n",
    "# une seule valeur, la probabilité maximum \n",
    "# dans le tableau complet, \n",
    "# en considérant l'ensemble des exemples \n",
    "y_test_best = np.argmax(y_test,1)\n",
    "print(y_test_best.shape)\n",
    "predictions_best = np.argmax(predictions,1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test_best, predictions_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devriez obtenir une précision autour de 91%, similaire à celle que nous avons obtenue dans les mêmes conditions avec scikit-learn. \n",
    "\n",
    "Le résultat n'est pas reproductible, et la précision variera à chaque fois que vous ré-entraînerez un nouveau réseau. Personnellement, j'obtiens généralement une précision entre 90 et 93%.  \n",
    "\n",
    "Et pour vous, que se passe-t'il lorsque vous répétez l'exercice? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
